{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPGv6kPpHcTxq9zkjh/5UWm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GouthamVicky/TextGeneration/blob/main/textpreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQjrE3ClMOhR"
      },
      "outputs": [],
      "source": [
        "Example_Sentence = \"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Machine learning algorithms build a mathematical model of sample data, known as “training data”, in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning and focuses on exploratory data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as predictive analytics.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#spaCy Code Initialization:\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "0WnhNZB9P4zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing using Spacy"
      ],
      "metadata": {
        "id": "fLTAwL4zQzOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spacy_process(text):\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    #Tokenization and lemmatization are done with the spacy nlp pipeline commands\n",
        "    lemma_list = []\n",
        "    for token in doc:\n",
        "        lemma_list.append(token.lemma_)\n",
        "    print(\"Tokenize+Lemmatize:\")\n",
        "    print(lemma_list)\n",
        "    \n",
        "    #Filter the stopword\n",
        "    filtered_sentence =[] \n",
        "    for word in lemma_list:\n",
        "        lexeme = nlp.vocab[word]\n",
        "        if lexeme.is_stop == False:\n",
        "            filtered_sentence.append(word) \n",
        "    \n",
        "    #Remove punctuation\n",
        "    punctuations=\"?:!.,;()@#$%^&*}{\"\n",
        "    for word in filtered_sentence:\n",
        "        if word in punctuations:\n",
        "            filtered_sentence.remove(word)\n",
        "    print(\" \")\n",
        "    print(\"Remove stopword & punctuation: \")\n",
        "    print(filtered_sentence)"
      ],
      "metadata": {
        "id": "-dEWfpR4P44f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_cleaned_text=spacy_process(Example_Sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtAD0MhcQOKY",
        "outputId": "338aeb18-9970-4968-efad-9eba3700eeaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenize+Lemmatize:\n",
            "['machine', 'learning', '(', 'ML', ')', 'be', 'the', 'scientific', 'study', 'of', 'algorithm', 'and', 'statistical', 'model', 'that', 'computer', 'system', 'use', 'to', 'progressively', 'improve', 'their', 'performance', 'on', 'a', 'specific', 'task', '.', 'machine', 'learning', 'algorithm', 'build', 'a', 'mathematical', 'model', 'of', 'sample', 'datum', ',', 'know', 'as', '\"', 'training', 'datum', '\"', ',', 'in', 'order', 'to', 'make', 'prediction', 'or', 'decision', 'without', 'be', 'explicitly', 'program', 'to', 'perform', 'the', 'task', '.', 'machine', 'learning', 'algorithm', 'be', 'use', 'in', 'the', 'application', 'of', 'email', 'filtering', ',', 'detection', 'of', 'network', 'intruder', ',', 'and', 'computer', 'vision', ',', 'where', 'it', 'be', 'infeasible', 'to', 'develop', 'an', 'algorithm', 'of', 'specific', 'instruction', 'for', 'perform', 'the', 'task', '.', 'machine', 'learning', 'be', 'closely', 'relate', 'to', 'computational', 'statistic', ',', 'which', 'focus', 'on', 'make', 'prediction', 'use', 'computer', '.', 'the', 'study', 'of', 'mathematical', 'optimization', 'deliver', 'method', ',', 'theory', 'and', 'application', 'domain', 'to', 'the', 'field', 'of', 'machine', 'learning', '.', 'datum', 'mining', 'be', 'a', 'field', 'of', 'study', 'within', 'machine', 'learning', 'and', 'focus', 'on', 'exploratory', 'datum', 'analysis', 'through', 'unsupervised', 'learning', '.', 'in', 'its', 'application', 'across', 'business', 'problem', ',', 'machine', 'learning', 'be', 'also', 'refer', 'to', 'as', 'predictive', 'analytic', '.']\n",
            " \n",
            "Remove stopword & punctuation: \n",
            "['machine', 'learning', 'ML', 'scientific', 'study', 'algorithm', 'statistical', 'model', 'computer', 'system', 'use', 'progressively', 'improve', 'performance', 'specific', 'task', 'machine', 'learning', 'algorithm', 'build', 'mathematical', 'model', 'sample', 'datum', 'know', '\"', 'training', 'datum', '\"', 'order', 'prediction', 'decision', 'explicitly', 'program', 'perform', 'task', 'machine', 'learning', 'algorithm', 'use', 'application', 'email', 'filtering', 'detection', 'network', 'intruder', 'computer', 'vision', 'infeasible', 'develop', 'algorithm', 'specific', 'instruction', 'perform', 'task', 'machine', 'learning', 'closely', 'relate', 'computational', 'statistic', 'focus', 'prediction', 'use', 'computer', 'study', 'mathematical', 'optimization', 'deliver', 'method', 'theory', 'application', 'domain', 'field', 'machine', 'learning', 'datum', 'mining', 'field', 'study', 'machine', 'learning', 'focus', 'exploratory', 'datum', 'analysis', 'unsupervised', 'learning', 'application', 'business', 'problem', 'machine', 'learning', 'refer', 'predictive', 'analytic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocesing using NLTK"
      ],
      "metadata": {
        "id": "q7_CWXv9Q7Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjMGbsCIRRYA",
        "outputId": "163dafc9-752e-49c8-9fc0-ca319168d204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize  \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "p_stemmer = PorterStemmer()\n",
        "#s_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "def nltk_process(text):\n",
        "    #Tokenization\n",
        "    nltk_tokenList = word_tokenize(text)\n",
        "    \n",
        "    #Stemming\n",
        "    nltk_stemedList = []\n",
        "    for word in nltk_tokenList:\n",
        "        nltk_stemedList.append(p_stemmer.stem(word))\n",
        "        #nltk_stemedList.append(s_stemmer.stem(word))\n",
        "    \n",
        "    #Lemmatization\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    nltk_lemmaList = []\n",
        "    for word in nltk_stemedList:\n",
        "        nltk_lemmaList.append(wordnet_lemmatizer.lemmatize(word))\n",
        "    \n",
        "    print(\"Stemming + Lemmatization\")\n",
        "    print(nltk_lemmaList)\n",
        "\n",
        "    #Filter stopword\n",
        "    filtered_sentence = []  \n",
        "    nltk_stop_words = set(stopwords.words(\"english\"))\n",
        "    for w in nltk_lemmaList:  \n",
        "        if w not in nltk_stop_words:  \n",
        "            filtered_sentence.append(w)  \n",
        "\n",
        "    #Removing Punctuation\n",
        "    punctuations=\"?:!.,;\"\n",
        "    for word in filtered_sentence:\n",
        "        if word in punctuations:\n",
        "            filtered_sentence.remove(word)\n",
        "    print(\" \")\n",
        "    print(\"Remove stopword & Punctuation\")\n",
        "    print(filtered_sentence)\n",
        "nltk_cleaned_text=nltk_process(Example_Sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2sF9OczQ-Pa",
        "outputId": "f6cf8377-ed94-400d-ed42-0ea0b1d9ec33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemming + Lemmatization\n",
            "['machin', 'learn', '(', 'ml', ')', 'is', 'the', 'scientif', 'studi', 'of', 'algorithm', 'and', 'statist', 'model', 'that', 'comput', 'system', 'use', 'to', 'progress', 'improv', 'their', 'perform', 'on', 'a', 'specif', 'task', '.', 'machin', 'learn', 'algorithm', 'build', 'a', 'mathemat', 'model', 'of', 'sampl', 'data', ',', 'known', 'a', '“', 'train', 'data', '”', ',', 'in', 'order', 'to', 'make', 'predict', 'or', 'decis', 'without', 'be', 'explicitli', 'program', 'to', 'perform', 'the', 'task', '.', 'machin', 'learn', 'algorithm', 'are', 'use', 'in', 'the', 'applic', 'of', 'email', 'filter', ',', 'detect', 'of', 'network', 'intrud', ',', 'and', 'comput', 'vision', ',', 'where', 'it', 'is', 'infeas', 'to', 'develop', 'an', 'algorithm', 'of', 'specif', 'instruct', 'for', 'perform', 'the', 'task', '.', 'machin', 'learn', 'is', 'close', 'relat', 'to', 'comput', 'statist', ',', 'which', 'focus', 'on', 'make', 'predict', 'use', 'comput', '.', 'the', 'studi', 'of', 'mathemat', 'optim', 'deliv', 'method', ',', 'theori', 'and', 'applic', 'domain', 'to', 'the', 'field', 'of', 'machin', 'learn', '.', 'data', 'mine', 'is', 'a', 'field', 'of', 'studi', 'within', 'machin', 'learn', 'and', 'focus', 'on', 'exploratori', 'data', 'analysi', 'through', 'unsupervis', 'learn', '.', 'in', 'it', 'applic', 'across', 'busi', 'problem', ',', 'machin', 'learn', 'is', 'also', 'refer', 'to', 'a', 'predict', 'analyt', '.']\n",
            " \n",
            "Remove stopword & Punctuation\n",
            "['machin', 'learn', '(', 'ml', ')', 'scientif', 'studi', 'algorithm', 'statist', 'model', 'comput', 'system', 'use', 'progress', 'improv', 'perform', 'specif', 'task', 'machin', 'learn', 'algorithm', 'build', 'mathemat', 'model', 'sampl', 'data', 'known', '“', 'train', 'data', '”', 'order', 'make', 'predict', 'decis', 'without', 'explicitli', 'program', 'perform', 'task', 'machin', 'learn', 'algorithm', 'use', 'applic', 'email', 'filter', 'detect', 'network', 'intrud', 'comput', 'vision', 'infeas', 'develop', 'algorithm', 'specif', 'instruct', 'perform', 'task', 'machin', 'learn', 'close', 'relat', 'comput', 'statist', 'focus', 'make', 'predict', 'use', 'comput', 'studi', 'mathemat', 'optim', 'deliv', 'method', 'theori', 'applic', 'domain', 'field', 'machin', 'learn', 'data', 'mine', 'field', 'studi', 'within', 'machin', 'learn', 'focus', 'exploratori', 'data', 'analysi', 'unsupervis', 'learn', 'applic', 'across', 'busi', 'problem', 'machin', 'learn', 'also', 'refer', 'predict', 'analyt']\n"
          ]
        }
      ]
    }
  ]
}